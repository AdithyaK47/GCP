# Introduction to Docker

Docker is a tool designed to make it easier to create, deploy, and run applications by using containers.
Containers allow a developer to package up an application with all of the parts it needs, such as libraries and other dependencies, and deploy it as one package. 

Containers can be thought of as necessitating three categories of software:
1. Builder: technology used to build a container.
2. Engine: technology used to run a container.
3. Orchestration: technology used to manage many containers.

One of the goals of modern software development is to keep applications on the same host or cluster isolated from one another so they don’t unduly interfere with each other’s operation or maintenance. 
This can be difficult, thanks to the packages, libraries, and other software components required for them to run.
One solution to this problem has been virtual machines, which keep applications on the same hardware entirely separate, 
and reduce conflicts among software components and competition for hardware resources to a minimum. 
But virtual machines are bulky—each requires its own OS, so is typically gigabytes in size—and difficult to maintain and upgrade.

Containers, by contrast, isolate applications’ execution environments from one another, but share the underlying OS kernel.
They’re typically measured in megabytes, use far fewer resources than VMs, and start up almost immediately. 
They can be packed far more densely on the same hardware and spun up and down en masse with far less effort and overhead. 
Containers provide a highly efficient and highly granular mechanism for combining software components into the kinds of application and service stacks needed in a modern enterprise, 
and for keeping those software components updated and maintained.

Docker is an open source project that makes it easy to create containers and container-based apps. Originally built for Linux, Docker now runs on Windows and MacOS as well.

Each Docker container starts with a Dockerfile. A Dockerfile is a text file written in an easy-to-understand syntax that includes the instructions to build a Docker image.
A Dockerfile specifies the operating system that will underlie the container, along with the languages, 
environmental variables, file locations, network ports, and other components it needs—and, of course, what the container will actually be doing once we run it.

The Dockerfile is the set of instructions that tells build how to make the image, 
a Docker image is a portable file containing the specifications for which software components the container will run and how. 

Docker’s run utility is the command that actually launches a container. Each container is an instance of an image. 
Containers are designed to be transient and temporary, but they can be stopped and restarted, which launches the container into the same state as when it was stopped.

Docker Engine is the core of Docker, the underlying client-server technology that creates and runs the containers.

While developers can create containers without Docker, Docker makes it easier, simpler, and safer to build, deploy, and manage containers. 
It’s essentially a toolkit that enables developers to build, deploy, run, update, and stop containers using simple commands and work-saving automation.

To monitor and manage container lifecycles in more complex environments, you’ll need to turn to a container orchestration tool. 
While Docker includes its own orchestration tool, called Docker Swarm, most developers choose Kubernetes instead.

Container orchestration automates the deployment, management, scaling, and networking of containers
It can help you to deploy the same application across different environments without needing to redesign it.
