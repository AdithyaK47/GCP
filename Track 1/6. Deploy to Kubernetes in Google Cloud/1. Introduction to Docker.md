# Introduction to Docker

# Notes

Docker is a tool designed to make it easier to create, deploy, and run applications by using containers.
Containers allow a developer to package up an application with all of the parts it needs, such as libraries and other dependencies, and deploy it as one package. 

Containers can be thought of as necessitating three categories of software:
1. Builder: technology used to build a container.
2. Engine: technology used to run a container.
3. Orchestration: technology used to manage many containers.

There are two ways of looking at Docker. The first approach involves seeing Docker containers as really lightweight virtual machines, 
while the second approach is to see Docker as a software packaging and delivery platform. 

Containers solve a critical issue in the life of application development. When developers are writing code they are working on their own local development environment. 
When they are ready to move that code to production this is where problems arise. The code that worked perfectly on their machine doesn’t work in production.
The reasons for this are varied; different operating system, different dependencies, different libraries. 

Containers solved this critical issue of portability allowing you to separate code from the underlying infrastructure it is running on. 
Developers could package up their application, including all of the bins and libraries it needs to run correctly, into a small container image. 
In production that container can be run on any computer that has a containerization platform.

Containers have an extremely small footprint. The container just needs its application and a definition of all of the bins and libraries it requires to run. 
Unlike VMs which each have a complete copy of a guest operating system, container isolation is done on the kernel level without the need for a guest operating system. 
In addition, libraries can be across containers, so it eliminates the need to have 10 copies of the same library on a server, further saving space. 
If I have 3 apps all running node and express, I don't have to have 3 instances of node and express, those apps can share those bins and libraries. 
Allowing for applications to become encapsulated in self-contained environments allows for quicker deployments, closer parity between development environments, and infinite scalability.

One of the goals of modern software development is to keep applications on the same host or cluster isolated from one another so they don’t unduly interfere with each other’s operation or maintenance. 
This can be difficult, thanks to the packages, libraries, and other software components required for them to run.
One solution to this problem has been virtual machines, which keep applications on the same hardware entirely separate, 
and reduce conflicts among software components and competition for hardware resources to a minimum. 
But virtual machines are bulky—each requires its own OS, so is typically gigabytes in size—and difficult to maintain and upgrade.

Containers, by contrast, isolate applications’ execution environments from one another, but share the underlying OS kernel.
They’re typically measured in megabytes, use far fewer resources than VMs, and start up almost immediately. 
They can be packed far more densely on the same hardware and spun up and down en masse with far less effort and overhead. 
Containers provide a highly efficient and highly granular mechanism for combining software components into the kinds of application and service stacks needed in a modern enterprise, 
and for keeping those software components updated and maintained.

Docker is an open source project that makes it easy to create containers and container-based apps. Originally built for Linux, Docker now runs on Windows and MacOS as well.

Each Docker container starts with a Dockerfile. A Dockerfile is a text file written in an easy-to-understand syntax that includes the instructions to build a Docker image.
A Dockerfile specifies the operating system that will underlie the container, along with the languages, 
environmental variables, file locations, network ports, and other components it needs—and, of course, what the container will actually be doing once we run it.

The Dockerfile is the set of instructions that tells build how to make the image, 
a Docker image is a portable file containing the specifications for which software components the container will run and how. 

Docker’s run utility is the command that actually launches a container. Each container is an instance of an image. 
Containers are designed to be transient and temporary, but they can be stopped and restarted, which launches the container into the same state as when it was stopped.

Docker Engine is the core of Docker, the underlying client-server technology that creates and runs the containers.

While developers can create containers without Docker, Docker makes it easier, simpler, and safer to build, deploy, and manage containers. 
It’s essentially a toolkit that enables developers to build, deploy, run, update, and stop containers using simple commands and work-saving automation.

To monitor and manage container lifecycles in more complex environments, you’ll need to turn to a container orchestration tool. 
While Docker includes its own orchestration tool, called Docker Swarm, most developers choose Kubernetes instead.

Container orchestration automates the deployment, management, scaling, and networking of containers
It can help you to deploy the same application across different environments without needing to redesign it.

While it is common to compare Kubernetes with Docker, a more apt comparison is Kubernetes vs. Docker Swarm. 
Docker Swarm is Docker’s orchestration technology that focuses on clustering for Docker containers—tightly integrated into the Docker ecosystem and using its own API.

A fundamental difference between Kubernetes and Docker is that Kubernetes is meant to run across a cluster while Docker runs on a single node. 
Kubernetes is more extensive than Docker Swarm and is meant to coordinate clusters of nodes at scale in production in an efficient manner. 
Kubernetes pods—scheduling units that can contain one or more containers in the Kubernetes ecosystem—are distributed among nodes to provide high availability.

One isn’t an alternative to the other. Quite the contrary; 
Kubernetes can run without Docker and Docker can function without Kubernetes. But Kubernetes can (and does) benefit greatly from Docker and vice versa.

It's pretty common to compare Kubernetes and Docker, however, a better comparison is Kubernetes vs Docker Swarm. 

Docker Swarm is orchestration technology similar to Kubernetes.
Docker Swarm is naturally tightly integrated within the Docker ecosystem and focuses on the clustering of Docker containers. 
A major difference between Docker and Kubernetes is that Docker runs on a single node, whereas Kubernetes is designed to run across a cluster. 
Another difference between Kubernetes and Docker is that Docker can be used without Kubernetes, whereas Kubernetes needs a container runtime in order to orchestrate.
As Kubernetes is a container orchestrator, it needs a container runtime in order to orchestrate. 
Kubernetes is most commonly used with Docker, but it can also be used with any container runtime. 
RunC, cri-o, containerd are other container runtimes that you can deploy with Kubernetes. 

Docker by itself will allow you to build container images, manage them in a registry, run containers and communicate with them, and put them together in a multi-container application using Docker Compose.

Kubernetes does not include functionality for creating or managing container images, and it does not, by itself, run containers; 
it needs to work with an external container source and runtime.

What Kubernetes does provide is a rich, flexible, and powerful framework for defining applications and orchestrating containers, at scale. 
It is well-designed for key enterprise-level tasks such as automated scaling, maintaining high availability, and operating in a multi-platform environment. 

Docker helps to “create” containers, and Kubernetes allows you to “manage” them at runtime. Use Docker for packaging and shipping the app. 
Employ Kubernetes to deploy and scale your app. Startups or small companies with fewer containers usually can manage them without having to use Kubernetes, 
but as the companies grow, their infrastructure needs will rise; hence, the number of containers will increase, which can be difficult to manage. T
his is where Kubernetes comes into play.

