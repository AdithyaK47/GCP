# Orchestrating the Cloud with Kubernetes

Kubernetes is an open source project which can run on many different environments, from laptops to high-availability multi-node clusters,                               
from public clouds to on-premise deployments, from virtual machines to bare metal.                                                                                

Deployments keep the pods up and running even when the nodes they run on fail.                                                                         

Create a deployment using Kubernetes (kubectl command)                                                                                                               
Expose it (Kubernetes creates an external Load Balancer with a public IP address attached to it)                                                                  
Here, Any client who hits that public IP address will be routed to the pods behind the service.                                                         

A Pod (as in a pod of whales or pea pod) is a group of one or more containers, with shared storage/network resources,                                              
and a specification for how to run the containers. A Pod's contents are always co-located and co-scheduled, and run in a shared context.                                   
Pods are the smallest deployable units of computing that one can create and manage in Kubernetes.                                                                 
           
Pods represent and hold a collection of one or more containers.                                                                                             
Generally, if one have multiple containers with a hard dependency on each other, package the containers inside a single pod.                                    
Pods also have Volumes. Volumes are data disks that live as long as the pods live, and can be used by the containers in that pod.                                
Pods provide a shared namespace for their contents which means that the containers inside of the pod can communicate with each other.                               
Pods also share a network namespace. This means that there is one IP Address per pod.                                                                                
 
By default, pods are allocated a private IP address and cannot be reached outside of the cluster.                                                                
Kubectl port-forward allows you to access and interact with internal Kubernetes cluster processes from the localhost.                                            
Map a local port to a port inside the pod.                                                                                                           
Interactive shell inside a Pod is available to control. This can come in handy when one want to troubleshoot from within a container.                             
 
Pods aren't meant to be persistent. They can be stopped or started for many reasons - like failed liveness or readiness checks - and this leads to a problem:             
What happens if one want to communicate with a set of Pods? When they get restarted they might have a different IP address.                                           
That's where Services come in. Services provide stable endpoints for Pods.                                                                        

Services use labels to determine what Pods they operate on. If Pods have the correct labels, they are automatically picked up and exposed by the services.        

The level of access a service provides to a set of pods depends on the Service's type. Currently there are three types:                       
ClusterIP (internal) -- the default type means that this Service is only visible inside of the cluster                                               
NodePort gives each node in the cluster an externally accessible IP                                                                                            
LoadBalancer adds a load balancer from the cloud provider which forwards traffic from the service to Nodes within it.                                             

Deployments are a declarative way to ensure that the number of Pods running is equal to the desired number of Pods, specified by the user.                             
The main benefit of Deployments is in abstracting away the low level details of managing Pods.                                                                      
Behind the scenes Deployments use Replica Sets to manage starting and stopping the Pods.                                                                               
If Pods need to be updated or scaled, the Deployment will handle that.                                                                                                
Deployment also handles restarting Pods if they happen to go down for some reason.                                                                                  

A ReplicaSet's purpose is to maintain a stable set of replica Pods running at any given time.                                                                        
As such, it is often used to guarantee the availability of a specified number of identical Pods.                                                                

